<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 5-4: 正規化層 - G-Test Note</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="assets/css/style.css">
    
    <!-- MathJax Configuration -->
    <script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            processEscapes: true,
            processEnvironments: true
        },
        options: {
            skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body class="chapter-magenta">
    <header class="header">
        <a href="index.html" class="logo">G-Test Note</a>
        <button class="hamburger" onclick="openMenu()">
            <i class="fas fa-bars"></i>
        </button>
    </header>

    <div class="container">
        <!-- Sidebar TOC -->
        <aside class="sidebar">
            <div class="chapter-title">Chapter 5-4: 正規化層</div>
            <nav class="toc" id="tableOfContents">
                <!-- TOC will be generated dynamically -->
            </nav>
        </aside>

        <!-- Main Content -->
        <main class="main-content study">
            <div class="content-header">
                <h1 class="content-title">Chapter 5-4</h1>
                <p class="content-subtitle">正規化層</p>
            </div>

            <div class="content">
                <h1 id="learning-objectives">学習目標</h1>
                <p>この章では以下の内容を学習します：</p>
                <ul>
                    <li><strong>正規化層の基礎的な知識</strong>を理解する</li>
                    <li><strong>代表的な正規化手法</strong>について理解する</li>
                    <li><strong>正規化層がディープラーニングモデルの学習において、どのような役割を果たすのか</strong>説明できる</li>
                </ul>

                <h2 id="keywords">キーワード</h2>
                <p><strong>グループ正規化</strong>, <strong>バッチ正規化</strong>, <strong>レイヤー正規化</strong>, <strong>インスタンス正規化</strong></p>

                <h1 id="what-is-normalization">正規化層とは</h1>
                <p><strong>正規化層（Normalization Layer）</strong>とは、ニューラルネットワークの各層において、データの分布を正規化（標準化）する処理を行う層のことです。</p>

                <h2 id="normalization-purpose">正規化の目的</h2>
                <ul>
                    <li><strong>内部共変量シフトの軽減</strong>: 学習中に各層の入力分布が変化する問題を解決</li>
                    <li><strong>学習の安定化</strong>: 勾配の爆発や消失を防ぎ、安定した学習を実現</li>
                    <li><strong>学習速度の向上</strong>: より大きな学習率を使用可能</li>
                    <li><strong>正則化効果</strong>: 過学習を抑制する効果</li>
                </ul>

                <h2 id="internal-covariate-shift">内部共変量シフト</h2>
                <p><strong>内部共変量シフト（Internal Covariate Shift）</strong>とは、ディープネットワークの学習中に、各層の入力分布が変化する現象です。</p>
                
                <h3 id="problems-without-normalization">正規化がない場合の問題</h3>
                <ul>
                    <li>前の層のパラメータ更新により、次の層の入力分布が変化</li>
                    <li>各層が常に変化する入力分布に適応する必要</li>
                    <li>学習が不安定になり、収束が困難</li>
                    <li>小さな学習率しか使用できない</li>
                </ul>

                <h1 id="batch-normalization">バッチ正規化（Batch Normalization）</h1>
                <p><strong>バッチ正規化（Batch Normalization, BN）</strong>は、2015年にIoffeとSzegedyによって提案された最も基本的な正規化手法です。</p>

                <h2 id="batch-norm-mechanism">バッチ正規化の仕組み</h2>
                <p>ミニバッチ内のデータに対して、各特徴量の平均を0、分散を1に正規化します。</p>

                <pre><code># バッチ正規化の数式
# μ: ミニバッチの平均
μ = (1/m) * Σ(x_i)

# σ²: ミニバッチの分散  
σ² = (1/m) * Σ(x_i - μ)²

# 正規化
x̂ = (x - μ) / √(σ² + ε)

# スケール・シフト変換
y = γ * x̂ + β</code></pre>

                <h3 id="batch-norm-parameters">学習可能パラメータ</h3>
                <ul>
                    <li><strong>γ（ガンマ）</strong>: スケールパラメータ（初期値: 1）</li>
                    <li><strong>β（ベータ）</strong>: シフトパラメータ（初期値: 0）</li>
                    <li>これらにより、正規化による表現能力の制限を回避</li>
                </ul>

                <h2 id="batch-norm-benefits">バッチ正規化の効果</h2>
                <ul>
                    <li><strong>学習の高速化</strong>: 大きな学習率が使用可能</li>
                    <li><strong>重み初期化への依存軽減</strong>: 初期値の影響を受けにくい</li>
                    <li><strong>正則化効果</strong>: Dropoutの必要性が減少</li>
                    <li><strong>勾配の安定化</strong>: 深いネットワークの学習が可能</li>
                </ul>

                <h2 id="batch-norm-limitations">バッチ正規化の制限</h2>
                <ul>
                    <li><strong>バッチサイズ依存</strong>: 小さなバッチサイズで性能低下</li>
                    <li><strong>推論時の課題</strong>: 学習時と推論時で処理が異なる</li>
                    <li><strong>RNNへの適用困難</strong>: 系列データでの使用が困難</li>
                    <li><strong>分散学習での問題</strong>: バッチ統計の同期が必要</li>
                </ul>

                <h1 id="layer-normalization">レイヤー正規化（Layer Normalization）</h1>
                <p><strong>レイヤー正規化（Layer Normalization, LN）</strong>は、バッチ次元ではなく特徴量次元で正規化を行う手法です。</p>

                <h2 id="layer-norm-mechanism">レイヤー正規化の仕組み</h2>
                <p>各サンプルの全特徴量に対して正規化を実行します。</p>

                <pre><code># レイヤー正規化の数式
# 各サンプルの特徴量次元で計算
μ = (1/H) * Σ(x_i)  # H: 特徴量数
σ² = (1/H) * Σ(x_i - μ)²

# 正規化とスケール・シフト
x̂ = (x - μ) / √(σ² + ε)
y = γ * x̂ + β</code></pre>

                <h2 id="layer-norm-advantages">レイヤー正規化の利点</h2>
                <ul>
                    <li><strong>バッチサイズ非依存</strong>: バッチサイズが1でも動作</li>
                    <li><strong>RNNに適用可能</strong>: 系列データで有効</li>
                    <li><strong>推論時の一貫性</strong>: 学習時と推論時で同じ処理</li>
                    <li><strong>Transformerで標準採用</strong>: 自然言語処理で広く使用</li>
                </ul>

                <h1 id="instance-normalization">インスタンス正規化（Instance Normalization）</h1>
                <p><strong>インスタンス正規化（Instance Normalization, IN）</strong>は、各サンプルの各チャンネルごとに正規化を行う手法です。</p>

                <h2 id="instance-norm-use-cases">インスタンス正規化の用途</h2>
                <ul>
                    <li><strong>スタイル転送</strong>: 画像のスタイル情報を除去</li>
                    <li><strong>生成モデル</strong>: GANでの画像生成</li>
                    <li><strong>テクスチャ合成</strong>: テクスチャパターンの生成</li>
                </ul>

                <pre><code># インスタンス正規化の処理範囲
# (N, C, H, W) のテンソルに対して
# 各 (n, c) について (H, W) 次元で正規化</code></pre>

                <h1 id="group-normalization">グループ正規化（Group Normalization）</h1>
                <p><strong>グループ正規化（Group Normalization, GN）</strong>は、チャンネルをグループに分割し、グループ内で正規化を行う手法です。</p>

                <h2 id="group-norm-concept">グループ正規化の概念</h2>
                <ul>
                    <li>チャンネル数Cを G個のグループに分割</li>
                    <li>各グループ内で正規化を実行</li>
                    <li>バッチ正規化とレイヤー正規化の中間的な手法</li>
                </ul>

                <pre><code># グループ正規化の例
# 32チャンネルを8グループに分割
# 各グループ4チャンネルで正規化</code></pre>

                <h2 id="group-norm-advantages">グループ正規化の利点</h2>
                <ul>
                    <li><strong>バッチサイズ非依存</strong>: 小さなバッチでも安定</li>
                    <li><strong>物体検出で有効</strong>: COCO datasetで良好な性能</li>
                    <li><strong>柔軟性</strong>: グループ数の調整が可能</li>
                </ul>

                <h1 id="normalization-comparison">正規化手法の比較</h1>

                <h2 id="comparison-table">特徴比較</h2>
                <table>
                    <thead>
                        <tr>
                            <th>手法</th>
                            <th>正規化範囲</th>
                            <th>バッチ依存</th>
                            <th>主な用途</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Batch Norm</strong></td>
                            <td>バッチ × チャンネル</td>
                            <td>あり</td>
                            <td>CNN（画像分類）</td>
                        </tr>
                        <tr>
                            <td><strong>Layer Norm</strong></td>
                            <td>特徴量次元</td>
                            <td>なし</td>
                            <td>RNN、Transformer</td>
                        </tr>
                        <tr>
                            <td><strong>Instance Norm</strong></td>
                            <td>各チャンネル</td>
                            <td>なし</td>
                            <td>スタイル転送、GAN</td>
                        </tr>
                        <tr>
                            <td><strong>Group Norm</strong></td>
                            <td>チャンネルグループ</td>
                            <td>なし</td>
                            <td>物体検出、小バッチ</td>
                        </tr>
                    </tbody>
                </table>

                <h2 id="selection-criteria">正規化手法の選択基準</h2>
                <ul>
                    <li><strong>画像分類（大バッチ）</strong>: Batch Normalization</li>
                    <li><strong>自然言語処理</strong>: Layer Normalization</li>
                    <li><strong>小バッチ・物体検出</strong>: Group Normalization</li>
                    <li><strong>スタイル転送</strong>: Instance Normalization</li>
                    <li><strong>生成モデル</strong>: Instance/Group Normalization</li>
                </ul>

                <h1 id="implementation-tips">実装上の注意点</h1>

                <h2 id="training-inference">学習時と推論時の違い</h2>
                <h3 id="batch-norm-inference">バッチ正規化の場合</h3>
                <ul>
                    <li><strong>学習時</strong>: ミニバッチ統計を使用</li>
                    <li><strong>推論時</strong>: 移動平均で計算した統計を使用</li>
                </ul>

                <pre><code># 推論時の統計更新（移動平均）
running_mean = momentum * running_mean + (1 - momentum) * batch_mean
running_var = momentum * running_var + (1 - momentum) * batch_var</code></pre>

                <h2 id="placement-tips">配置位置</h2>
                <ul>
                    <li><strong>一般的</strong>: 線形変換 → 正規化 → 活性化関数</li>
                    <li><strong>ResNet</strong>: 正規化 → 活性化関数 → 線形変換</li>
                    <li><strong>Transformer</strong>: Pre-LN vs Post-LN の議論</li>
                </ul>

                <h1 id="latest-trends">最新動向と発展</h1>

                <h2 id="advanced-normalizations">新しい正規化手法</h2>
                <ul>
                    <li><strong>RMSNorm</strong>: 平均を0に固定、分散のみ正規化</li>
                    <li><strong>LayerScale</strong>: 層ごとのスケーリング</li>
                    <li><strong>BatchNorm++</strong>: バッチ正規化の改良版</li>
                </ul>

                <h2 id="normalization-free">正規化フリーな手法</h2>
                <ul>
                    <li><strong>NFNet</strong>: 正規化を使わないネットワーク</li>
                    <li><strong>SkipInit</strong>: 初期化の工夫による正規化の代替</li>
                </ul>

                <h1 id="summary">まとめ</h1>
                <ul>
                    <li><strong>正規化層</strong>は深層学習において重要な技術</li>
                    <li><strong>バッチ正規化</strong>が最も一般的だが、制限もある</li>
                    <li><strong>タスクやアーキテクチャ</strong>に応じて適切な正規化手法を選択</li>
                    <li><strong>内部共変量シフト</strong>の軽減が主な目的</li>
                    <li><strong>学習の安定化と高速化</strong>に大きく貢献</li>
                    <li>正規化手法の研究は現在も活発に進行中</li>
                </ul>

                <h1 id="glossary">主な用語集</h1>
                
                <h2 id="key-terms">重要用語</h2>
                <dl style="margin: 20px 0;">
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">内部共変量シフト（Internal Covariate Shift）</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">学習中に各層の入力分布が変化する現象。正規化により軽減される。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">バッチ正規化（Batch Normalization）</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">ミニバッチ統計を用いて各特徴量を正規化。最も広く使用される手法。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">レイヤー正規化（Layer Normalization）</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">各サンプルの特徴量次元で正規化。RNNやTransformerで使用。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">インスタンス正規化（Instance Normalization）</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">各チャンネルごとに正規化。スタイル転送やGANで使用。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">グループ正規化（Group Normalization）</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">チャンネルをグループ分割して正規化。小バッチで有効。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">γ（ガンマ）・β（ベータ）パラメータ</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">正規化後のスケール（γ）とシフト（β）を調整する学習可能パラメータ。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">移動平均（Moving Average）</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">バッチ正規化の推論時に使用する統計量の計算方法。</dd>
                </dl>

                <h1 id="key-points">試験対策キーポイント</h1>
                
                <h2 id="exam-essentials">必須暗記ポイント</h2>
                <div style="background-color: #1a1a1a; border: 3px solid #ff00ff; padding: 20px; margin: 20px 0;">
                    <h3 style="color: #ff00ff; margin-top: 0;">📝 正規化手法の特徴</h3>
                    <ul>
                        <li><strong>Batch Norm</strong>: バッチ統計、CNN向け、バッチサイズ依存</li>
                        <li><strong>Layer Norm</strong>: 特徴量統計、RNN/Transformer向け、バッチ非依存</li>
                        <li><strong>Instance Norm</strong>: チャンネル統計、スタイル転送向け</li>
                        <li><strong>Group Norm</strong>: グループ統計、物体検出向け、小バッチOK</li>
                    </ul>
                </div>

                <div style="background-color: #1a1a1a; border: 3px solid #ff00ff; padding: 20px; margin: 20px 0;">
                    <h3 style="color: #ff00ff; margin-top: 0;">⚡ バッチ正規化の効果</h3>
                    <ul>
                        <li>学習の<strong>高速化</strong>（大きな学習率が使用可能）</li>
                        <li>重み初期化への<strong>依存軽減</strong></li>
                        <li><strong>正則化効果</strong>（過学習抑制）</li>
                        <li>勾配の<strong>安定化</strong>（深いネットワーク学習可能）</li>
                    </ul>
                </div>

                <div style="background-color: #1a1a1a; border: 3px solid #ff00ff; padding: 20px; margin: 20px 0;">
                    <h3 style="color: #ff00ff; margin-top: 0;">🔍 よく出る問題パターン</h3>
                    <ul>
                        <li><strong>用途別選択</strong>: 「○○タスクに適した正規化手法は？」</li>
                        <li><strong>バッチサイズ影響</strong>: 「バッチサイズが小さい時の課題は？」</li>
                        <li><strong>学習・推論の違い</strong>: 「バッチ正規化の推論時処理は？」</li>
                        <li><strong>パラメータ数</strong>: 「γ、βパラメータの役割は？」</li>
                    </ul>
                </div>

                <h2 id="formula-summary">重要公式まとめ</h2>
                <div style="background-color: #1a1a1a; border: 3px solid #ff00ff; padding: 20px; margin: 20px 0;">
                    <h3 style="color: #ff00ff; margin-top: 0;">📐 バッチ正規化の基本式</h3>
                    <pre style="margin: 10px 0;"><code>平均: μ = (1/m) * Σx_i
分散: σ² = (1/m) * Σ(x_i - μ)²
正規化: x̂ = (x - μ) / √(σ² + ε)
出力: y = γx̂ + β</code></pre>
                </div>

                <h2 id="common-mistakes">よくある間違い</h2>
                <div style="background-color: #1a1a1a; border: 3px solid #000000; padding: 20px; margin: 20px 0;">
                    <h3 style="color: #ffffff; margin-top: 0;">❌ 注意すべきポイント</h3>
                    <ul>
                        <li>Layer NormとInstance Normの<strong>正規化範囲</strong>を混同</li>
                        <li>バッチ正規化の<strong>推論時処理</strong>を学習時と同じと思う</li>
                        <li>正規化手法の<strong>適用分野</strong>を間違える</li>
                        <li>γ、βパラメータの<strong>初期値</strong>を覚えていない</li>
                    </ul>
                </div>

                <!-- Page Navigation -->
                <nav class="page-nav" style="border-top: 3px solid #000000; padding-top: 40px; margin-top: 40px;">
                    <div style="display: flex; justify-content: space-between; align-items: center;">
                        <a href="study5-3.html" style="color: #ffffff; text-decoration: none; border: 3px solid #000000; padding: 15px 20px; text-transform: uppercase; font-weight: 600; transition: all 0.2s ease;">
                            <i class="fas fa-chevron-left" style="margin-right: 8px; color: #ff00ff;"></i>
                            Back
                        </a>

                        <a href="study5-5.html" style="color: #ffffff; text-decoration: none; border: 3px solid #000000; padding: 15px 20px; text-transform: uppercase; font-weight: 600; transition: all 0.2s ease;">
                            Next
                            <i class="fas fa-chevron-right" style="margin-left: 8px; color: #ff00ff;"></i>
                        </a>
                    </div>
                </nav>
            </div>
        </main>
    </div>

    <!-- Hamburger Menu -->
    <div class="menu-overlay" id="menuOverlay">
        <div class="menu-header">
            <div class="menu-title">Menu</div>
            <button class="close-btn" onclick="closeMenu()">
                <i class="fas fa-times"></i>
            </button>
        </div>
        
        <ul class="menu-items">
            <li class="menu-item">
                <a href="sitemap.html" class="menu-link">
                    <i class="fas fa-map" style="margin-right: 8px; color: #ffffff;"></i>
                    Sitemap
                </a>
            </li>
            <li class="menu-item">
                <a href="help.html" class="menu-link">
                    <i class="fas fa-question-circle" style="margin-right: 8px; color: #ffffff;"></i>
                    Help
                </a>
            </li>
            <li class="menu-item">
                <a href="settings.html" class="menu-link">
                    <i class="fas fa-cog" style="margin-right: 8px; color: #ffffff;"></i>
                    Settings
                </a>
            </li>
        </ul>
    </div>

    <script src="assets/js/main.js"></script>
    <script src="assets/js/toc-generator.js"></script>
    <script>
        // Initialize page
        document.addEventListener('DOMContentLoaded', function() {
            // Generate table of contents from existing HTML content
            generateTableOfContents();
        });
    </script>
</body>
</html>