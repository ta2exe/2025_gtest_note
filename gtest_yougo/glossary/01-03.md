# 第1〜3章 人工知能と機械学習の概説 用語集

本ファイルは第1〜3章を1つに集約し、各節ごとに表を分けてシラバス順で掲載します。

## 第1章 人工知能とは

### 1. 人工知能の定義（キーワード）

| 用語（日本語） | 用語英語（略語） | 解説 | POINT |
|---|---|---|---|
| 人工知能 | artificial intelligence (AI) | 人工的に知的な振る舞いを示すシステムの総称。単純な制御から記号的AI、機械学習、深層学習まで含む。 | 目的（何をできるようにするか）と手段を混同しない。 |
| 機械学習 | machine learning (ML) | データから規則・関数を学習し予測や判断を行う手法群。教師あり・教師なし・強化学習に大別。 | ルールベースとの違い（経験から学ぶ）を押さえる。 |
| ディープラーニング | deep learning (DL) | 多層ニューラルネットで表現学習とタスク最適化を同時に行う学習法。 | 画像・言語・音声での性能向上を牽引。データと計算資源が鍵。 |
| AI効果 | AI effect | かつてAIと呼ばれた技術が陳腐化するとAIではないと見なされる現象。 | 歴史的に繰り返し。期待値の管理に有用。 |
| エージェント | agent | 環境を観測し方策に従って行動、目的（報酬等）を最適化する主体の抽象。 | センサー・アクチュエータ・方策・価値の枠組みを理解。 |

### 2. 人工知能分野で議論される問題（キーワード）

| 用語（日本語） | 用語英語（略語） | 解説 | POINT |
|---|---|---|---|
| シンギュラリティ | technological singularity | 技術進歩が指数加速し、人間の理解や予測を超える転換点が来るとする仮説。 | 賛否が割れる概念論。年号断定は根拠薄。 |
| シンボルグラウンディング問題 | symbol grounding problem | 記号の意味を知覚や身体的経験にどう結び付けるかの問題。 | 身体性や自己教師あり学習の議論に接続。 |
| 身体性 | embodiment | 知能は身体と環境相互作用に基づくという立場。 | ロボティクスや認知科学の基礎概念。 |
| ダートマス会議 | Dartmouth conference | 1956年の研究集会。AIという語の起点。 | 人名暗記より意義を理解。 |
| トイ・プロブレム | toy problem | 検証のために単純化された問題。 | 一般化の限界と移植条件を意識。 |
| 知識獲得のボトルネック | knowledge acquisition bottleneck | ルール抽出・形式化・保守の高コストがボトルネックとなる問題。 | データ駆動や統計的手法への転換の背景。 |
| チューリングテスト | Turing test | 対話で人と区別できなければ知能と見なす操作的定義。 | 「合格=本質的知能」ではない。 |
| 中国語の部屋 | Chinese room argument | 記号操作だけでは意味理解に至らないとする思考実験（セアール）。 | 強いAI批判。意味接地の必要性。 |
| 強いAIと弱いAI | strong AI vs. weak AI | 強いAIは心的状態・理解を持つ主張、弱いAIは有用な機能実現に限定。 | 試験では定義の違いを問われがち。 |
| 統計的機械翻訳 | statistical machine translation (SMT) | 統計モデルにより翻訳を行う手法群（n-gram、IBMモデル等）。 | NMT普及前の主流。対比として押さえる。 |
| ルールベース機械翻訳 | rule-based MT (RBMT) | 辞書・文法規則に基づく翻訳。 | ドメイン内で高精度だが拡張性が課題。 |
| フレーム問題 | frame problem | 何が不変かを記述・推論する困難さ。 | 計画・常識推論で顕在化。 |
| ローブナーコンテスト | Loebner prize | チューリングテスト形式の対話コンテスト。 | 歴史事項。評価の限界も併記されることが多い。 |

## 第2章 人工知能をめぐる動向

### 3. 探索・推論（キーワード）

| 用語（日本語） | 用語英語（略語） | 解説 | POINT |
|---|---|---|---|
| 探索木 | search tree | 状態と行動の展開木で解を探索する枠組み。 | 完全性・最適性・計算量を比較。 |
| ハノイの塔 | Tower of Hanoi | 円盤移動パズル。再帰的構造を持つ典型的探索課題。 | 最小手数は2^n−1。 |
| 幅優先探索 | breadth-first search (BFS) | 階層ごとに探索。最短経路を見つけるがメモリ大。 | キュー実装。無重み最短路に有効。 |
| 深さ優先探索 | depth-first search (DFS) | 深く掘って戻る探索。メモリ小。 | 無限ループ対策が必要。 |
| ブルートフォース | brute force | 総当たり探索。小規模問題で有効。 | 枝刈りやヒューリスティックと併用。 |
| ミニマックス法 | minimax | ゼロ和二人ゲームで相手最善を仮定して行動選択。 | 評価関数と探索深さの設計が鍵。 |
| αβ法（枝刈り） | alpha-beta pruning | ミニマックスの不要分岐を刈り計算削減。 | 節点順序で効果が大きく変わる。 |
| モンテカルロ法 | Monte Carlo method | 乱択サンプリングで期待値/勝率を推定。 | サンプル数・乱数の質に依存。 |
| SHRDLU | SHRDLU | ブロック世界の自然言語対話システム。 | 限定世界では高性能。汎用性は限定。 |
| STRIPS | STRIPS | 古典計画言語。前提と効果で行動を定義し計画を導出。 | 不確実性・連続量は拡張で対応。 |

### 4. 知識表現とエキスパートシステム（キーワード）

| 用語（日本語） | 用語英語（略語） | 解説 | POINT |
|---|---|---|---|
| Cyc プロジェクト | Cyc project | 常識知識を体系化する長期プロジェクト。 | is-a/part-of など関係表現の基盤。 |
| DENDRAL | DENDRAL | 化学構造推定の初期エキスパートシステム。 | ドメイン知識の有効性を示した。 |
| is-a/has-a/part-of | is-a / has-a / part-of | クラス包含・属性所有・部分全体の基本関係。 | オントロジー/知識グラフの基礎。 |
| 質問応答 | question answering (QA) | 自然言語の質問に回答を返すシステム。 | 検索型/生成型/RAGなど方式多様。 |
| 意味ネットワーク | semantic network | 概念と関係をグラフで表す知識表現。 | 推論はスプレッドアクティベーション等。 |
| ELIZA | ELIZA | パターン照合による初期対話システム。 | 理解なき応答の限界を示す例。 |
| インタビューシステム | interview system | 質疑応答で知識を取得・診断するシステム。 | 専門領域の画一化された聞き取りに有効。 |
| ウェブマイニング | web mining | Webデータからの知識抽出（構造/内容/利用）。 | 収集バイアスと倫理に注意。 |
| オントロジー | ontology | 概念体系と関係性の形式的定義。 | ドメインモデリングの基盤。 |
| セマンティックWeb | semantic web | Webに意味情報（RDF/OWL）を付与し機械可読化を図る構想。 | 実装・標準化・運用の難しさあり。 |
| データマイニング | data mining | 大量データからのパターン発見。 | 統計的有意と実務上の有用性を区別。 |
| 東ロボくん | Todai Robot Project | 大学入試問題に挑むAI研究プロジェクト。 | 自然言語理解と常識推論の課題を顕在化。 |
| マイシン | MYCIN | 医療（感染症）向けエキスパートシステム。 | ルールベース診断の代表例。 |
| ワトソン | IBM Watson | クイズ番組で勝利したQAシステム。 | 大規模知識・統計的手法の統合。 |

### 5. 機械学習（キーワード）

| 用語（日本語） | 用語英語（略語） | 解説 | POINT |
|---|---|---|---|
| 次元の呪い | curse of dimensionality | 次元増加でデータが疎になり距離や密度の直感が崩れる現象。 | 特徴選択/次元削減/正則化で対処。 |
| スパムフィルター | spam filter | 迷惑メール判別の応用例。 | 教師あり学習の典型タスク。 |
| ビッグデータ | big data | 大量・多様・高速生成されるデータ群。 | 3V/5V等の定義。品質管理が重要。 |
| レコメンデーションエンジン | recommendation engine | 協調/コンテンツベース等でアイテム推薦を行う。 | コールドスタート・多腕バンディット対策。 |

### 6. ディープラーニング（キーワード）

| 用語（日本語） | 用語英語（略語） | 解説 | POINT |
|---|---|---|---|
| ImageNet | ImageNet | 画像大規模データセット。ILSVRCでDL躍進の起点。 | クラス数・分解能・分布の偏りに留意。 |
| ILSVRC | ILSVRC | ImageNet Large Scale Visual Recognition Challenge。 | 2012年以降CNNがブレークスルー。 |
| LeNet | LeNet | 手書き数字認識の初期CNN。 | 畳み込み+プーリングの原型。 |
| アルファ碁 | AlphaGo | 強化学習とMCTSを統合した囲碁AI。 | 自己対戦・価値/方策ネットの活用。 |
| 人間の神経回路 | human neural circuit | 脳の神経回路に着想を得た比喩的説明。 | 生物学的詳細との乖離に注意。 |
| ネオコグニトロン | neocognitron | 層状の特徴抽出モデル。CNNの先駆。 | S細胞/C細胞の構造。 |
| 大規模言語モデル | large language model (LLM) | 大規模語料で事前学習した生成モデル。 | Transformer系が主流。 |

## 第3章 機械学習の概要

### 7. 教師あり学習（キーワード）

| 用語（日本語） | 用語英語（略語） | 解説 | POINT |
|---|---|---|---|
| 教師あり学習 | supervised learning | 特徴量Xと正解ラベルyのペアから写像f: X→yを学習する枠組み。主なタスクは回帰と分類で、損失（MSE/交差エントロピー）と評価指標（RMSE/精度・適合率・再現率・AUC等）を選ぶ。過学習を監視し、検証データや正則化・早期終了を用いる。 | データ分割（train/valid/test）とデータ漏洩防止が最重要。特徴量の前処理とスケーリングを整える。 |
| 回帰問題 | regression | 連続値の予測を行う設定。誤差の分布や外れ値の有無で損失（MSE/MAE/Huber）を選択し、尺度の違いは標準化で緩和する。予測区間や残差の分析で妥当性を確認する。 | 損失はMSEが標準だが外れ値に敏感。スケーリングと評価指標の整合に注意。 |
| 分類問題 | classification | 離散ラベルの予測。二値/多クラス/多ラベルがあり、確率出力の校正（Platt/Isotonic）や閾値最適化で実運用に合わせる。クラス不均衡には重み付けやリサンプリングを用いる。 | 精度だけでなくROC-AUC/PR-AUC、業務コストで閾値設定。 |
| 線形回帰 | linear regression | 入力の線形結合で目的変数を近似。推定は最小二乗が基本で、仮定（独立同分布・等分散・線形性）を外すと性能が低下する。 | 多重共線性（VIF）や外れ値の影響に注意。正則化（L1/L2）で安定化。 |
| 重回帰分析 | multiple regression | 複数説明変数の線形回帰。交互作用や多項式基底で非線形を近似できるが、過学習のリスクが増す。 | 変数選択（逐次/情報量基準）や正則化（L1/L2）で制御。 |
| ロジスティック回帰 | logistic regression | シグモイドで確率化する二値分類。 | 多クラスは一対他/softmax回帰。 |
| 決定木 | decision tree | 質問分割で予測する木構造モデル。 | 深さと剪定で汎化を調整。 |
| ランダムフォレスト | random forest | ブートストラップと特徴部分空間で木のアンサンブル。 | 高精度・頑健だが解釈は相対的に難。 |
| バギング | bagging | データ再標本化で複数学習→平均化。 | バリアンス低減。 |
| ブースティング | boosting | 弱学習器を逐次強化して強学習器に。 | 勾配ブースティング/Adaboost等。 |
| 勾配ブースティング | gradient boosting | 残差を次モデルで近似し加算。 | 学習率/木深さ/正則化で過学習抑制。 |
| AdaBoost | AdaBoost | 重み付け再学習で誤分類を強調。 | 外れ値に弱い。 |
| アンサンブル学習 | ensemble learning | 複数モデルを組み合わせ性能向上。 | 多様性の確保が鍵。 |
| カーネル | kernel | 内積を高次特徴空間の類似として拡張。 | 正定値性・ハイパラ選択。 |
| カーネルトリック | kernel trick | 明示写像なしに非線形学習を実現。 | SVM/カーネル回帰で使用。 |
| サポートベクターマシン | support vector machine (SVM) | マージン最大化に基づく分類器。 | ソフトマージン/C・カーネル選択が性能を左右。 |
| 自己回帰モデル | autoregressive model (AR) | 時系列の過去値から現在を回帰。 | 次数選択と定常性。 |
| ベクトル自己回帰 | vector autoregression (VAR) | 多変量時系列の相互依存を同時に扱う。 | 次数・安定条件に注意。 |
| 多クラス分類 | multiclass classification | 3クラス以上の分類。 | one-vs-rest/one-vs-one/softmax。 |
| ブートストラップサンプリング | bootstrap sampling | 復元抽出で再標本化する手法。 | 推定の不確実性評価に有用。 |
| マージン最大化 | margin maximization | クラス間の間隔を最大化する設計思想。 | SVMの核。汎化とロバスト性に寄与。 |

### 8. 教師なし学習（キーワード）

| 用語（日本語） | 用語英語（略語） | 解説 | POINT |
|---|---|---|---|
| 教師なし学習 | unsupervised learning | 正解ラベルのない特徴量Xのみから構造を見出す枠組み。代表はクラスタリング、次元削減、異常検知、密度推定。評価は内的指標/外的指標/ダウンストリーム性能で間接的に行う。 | スケール感と距離の選択が結果を左右。前処理（標準化/正規化）を統一。 |
| クラスタリング | clustering | 類似インスタンスを群に分ける。 | 内部/外部評価指標を使い分け。 |
| k-means 法 | k-means | セントロイドに最近傍割当→再計算を反復。球状クラスタ・同一分散の仮定に強く依存し、外れ値や非凸分布に弱い。 | 初期値/クラスタ数依存。スケールと特徴量の重み付けに注意。 |
| ウォード法 | Ward linkage | 階層的クラスタリングのリンク法の一つ。分散最小化基準。 | デンドログラムのカットでクラスタ数決定。 |
| デンドログラム | dendrogram | 階層的クラスタリングの樹形図。 | 可視化解釈の支援。 |
| 主成分分析 | principal component analysis (PCA) | 共分散行列の固有分解に基づき、分散最大の直交軸へ射影して次元削減する。情報の圧縮・可視化・前処理に広く用いられる。 | 特徴量のスケールを事前に標準化。寄与率・累積寄与率で軸数を決定。 |
| 特異値分解 | singular value decomposition (SVD) | 行列分解で低ランク近似や次元削減に利用。 | 数値安定性と計算コスト。 |
| t-SNE | t-SNE | 高次元データの低次元可視化。局所構造を保持。 | パラメータ依存が大きく定量比較に不向き。 |
| 潜在的ディリクレ配分法 | latent Dirichlet allocation (LDA) | 文書をトピックの混合とみなす生成モデル。 | 対数尤度/コヒーレンスで評価。 |
| トピックモデル | topic model | 文書集合の隠れテーマを抽出するモデル群。 | LDA以外にNMF/CTM等。 |
| 次元削減 | dimensionality reduction | 情報を保ちながら次元を下げる手法の総称。 | 可視化/学習前処理で活用。 |
| 協調フィルタリング | collaborative filtering | 類似ユーザ/アイテムから嗜好を推定。 | コールドスタート/スパース性対応が課題。 |
| コンテンツベースフィルタリング | content-based filtering | アイテム属性に基づく推薦。 | 特徴設計の質に依存。 |
| コールドスタート問題 | cold-start problem | 新規ユーザ/アイテムでデータ不足により推薦が難しい問題。 | メタデータ活用/探索的提示で緩和。 |

### 9. 強化学習（キーワード）

| 用語（日本語） | 用語英語（略語） | 解説 | POINT |
|---|---|---|---|
| 強化学習 | reinforcement learning (RL) | 環境と相互作用しながら試行錯誤で方策を学ぶ枠組み。MDPで定式化し、価値ベース（Q学習/DQN）と方策ベース（REINFORCE/Actor-Critic）に大別。探索と活用のバランス、サンプル効率、安定性が主要論点。 | オン/オフポリシー、オン/オフライン学習の違いを整理。報酬設計と安全性に注意。 |
| マルコフ決定過程 | Markov decision process (MDP) | 状態・行動・遷移・報酬・割引で環境を定式化。 | ベルマン方程式が中核。 |
| 割引率 | discount factor (γ) | 将来報酬の現在価値を決める係数。 | 0<γ<1。高すぎると不安定化も。 |
| 行動価値関数 | action-value function (Q) | 状態・行動の期待累積報酬。 | Q学習/Deep Qで直接近似。 |
| 状態価値関数 | state-value function (V) | 状態の期待累積報酬。 | 価値反復/方策反復で利用。 |
| e-greedy 方策 | epsilon-greedy policy | εの確率で探索、1−εで活用。 | 探索率のスケジューリングが鍵。 |
| UCB 方策 | upper confidence bound (UCB) | 信頼上界で探索と活用を理論的に両立。 | 多腕バンディットで典型。 |
| 方策勾配法 | policy gradient | 方策を確率的にパラメタ化し勾配上昇。 | バリアンス低減にベースライン（Advantage）。 |
| REINFORCE | REINFORCE | 方策勾配の基本手法。 | 分散が大きい→Actor-Criticへ発展。 |
| Actor-Critic | actor-critic | 方策（Actor）と価値（Critic）を同時学習。 | GAEやTarget Networkで安定化。 |
| Q学習 | Q-learning | ブートストラップでQを更新。 | オフポリシー。関数近似で発散注意→DQN。 |

### 10. モデルの選択・評価（キーワード）

| 用語（日本語） | 用語英語（略語） | 解説 | POINT |
|---|---|---|---|
| モデルの選択・評価 | model selection and evaluation | 過学習を避け汎化性能を最大化するために、データ分割（train/valid/test）や交差検証で性能を推定し、目的に合う指標で比較・選択するプロセス。閾値設定や確率校正、外部テストで実運用に合わせる。 | データ漏洩を防ぎ、ハイパラ探索は検証データのみで行う。最終評価はテストデータを一度だけ使う。 |
| 交差検証 | cross validation | データ分割で汎化性能を推定する枠組み。 | k分割/ホールドアウト/LOOCV等。 |
| k-分割交差検証 | k-fold cross validation | データをk分割し、k回学習・検証を回して平均性能を得る。分散が小さく安定した推定になるが計算コストは増える。 | 層化k-foldでラベル分布を保存。時系列は時系列CVを用いる。 |
| ホールドアウト検証 | hold-out validation | 学習/検証/テストに分割して評価。 | データ漏洩防止が最重要。 |
| 過学習 | overfitting | 訓練データに特化して未知データで性能が落ちる現象。複雑すぎるモデル、データ不足、リークが原因になりやすい。 | 正則化/データ拡張/早期終了/ドロップアウト、特徴量とラベルのリーク監査。 |
| 偽陽性・偽陰性 | FP/FN | 誤検出/見逃し。 | タスクでコストが異なる→閾値最適化。 |
| 混同行列 | confusion matrix | 予測と正解のクロス集計。 | 指標計算の基礎。 |
| 正解率・適合率・再現率・F値 | accuracy/precision/recall/F1 | 分類評価の基本指標。 | 不均衡データで正解率は当てにならない。 |
| ROC 曲線・AUC | ROC / AUC | 閾値を動かしたTPR-FPRの関係とその面積。 | 不均衡下でも比較可能。 |
| MSE・RMSE・MAE | MSE / RMSE / MAE | 回帰の誤差指標。MSEは大誤差を強く罰し、MAEは外れ値に頑健、RMSEはMSEの尺度を元に戻したもの。 | 目的と分布に応じて選択。評価は残差プロットも併用。 |
| 汎化性能 | generalization performance | 未知データでの性能。 | 検証設計とデータ品質が支配。 |
| AIC | Akaike information criterion (AIC) | 当てはまりと自由度のトレードオフでモデル選択。 | 低いほど良い。比較は同一データで。 |
| BIC | Bayesian information criterion (BIC) | AICに対し自由度への罰則が強い。 | サンプルサイズが大きいと単純モデルを選びやすい。 |
| バイアス・バリアンスのトレードオフ | bias–variance trade-off | 予測誤差は概ね$\mathbb{E}[(\hat f(x)-f(x))^2]=\text{Bias}^2+\text{Variance}+\sigma^2$に分解できる。モデルが単純すぎるとバイアスが支配、複雑すぎるとバリアンス（過学習）が支配する。学習曲線で適正な複雑さを見極める。 | 正則化強度や特徴次元、木の深さ、カーネル幅などで複雑さを調整。データ量やノイズ水準に応じて最適点が変わる。 |
| 過学習（補足） | overfitting (details) | 訓練データの偶然のノイズやスプリアス相関まで拾うことで未知データ性能が低下。原因はモデル容量過大、データ不足や分布ずれ、評価設計の不備（リーク）など。兆候は「訓練損失は下がり続けるのに検証損失が下げ止まり→上昇」「大きな汎化ギャップ」など。 | 対策: 容量削減・特徴選択、正則化（L1/L2/重み減衰）、データ拡張、早期終了、ドロップアウト、適切なCV設計と前処理順序の厳守。 |
| データリーケージ | data leakage | 学習時に使えない情報が意図せず学習/検証に混入し、過大評価を招く問題。例: スケーリングを全データでfit、目標に直結する特徴、将来情報を混ぜる時系列、同一個体が学習と検証に跨る。 | 分割→前処理→学習の順序を厳守。パイプライン化、Group/TimeSeriesCV、特徴監査で防止。 |
### 補足（第3章の重要概念の詳細）

| 用語（日本語） | 用語英語（略語） | 解説 | POINT |
|---|---|---|---|
| ロジスティック回帰（補足） | logistic regression (details) | 尤度最大化で$P(y=1\mid x)=\sigma(w^\top x)$を学習。対数オッズ$\log\tfrac{p}{1-p}$が線形になるため、係数の符号と大きさは「増減の方向と強さ」の解釈に直結する。正則化（L1/L2）は過学習抑制だけでなく、多重共線性の緩和や特徴選択にも効く。 | スケーリングを整え、確率の校正（Platt/Isotonic）と閾値最適化で実運用に合わせる。 |
| 決定木（補足） | decision tree (details) | 分割基準（ジニ/エントロピー/分散減少）で情報利得が最大となる質問を選ぶ貪欲法。高次元の相互作用や非線形境界を自然に表現できる一方、深い木は分散が増えて過学習しやすい。 | 深さ/葉最小サンプル/剪定で制御。カテゴリ変数の扱いと欠損の分岐方針を明示。 |
| ランダムフォレスト（補足） | random forest (details) | ブートストラップ標本ごとに異なる特徴部分空間で木を育て、平均化で分散を低減。相関の小さい木を多数用意するほど汎化が安定する。 | OOB（袋外）推定で汎化性能を追加データなしに見積もれる。重要度指標のバイアスに注意。 |
| 勾配ブースティング（補足） | gradient boosting (details) | 目的損失の負勾配を関数空間で近似し、弱学習器を逐次加算（関数勾配法）。学習率を小さくし木を浅く多数重ねるのが定石。XGBoost/LightGBM/CatBoostなど実装ごとの正則化が重要。 | 早期終了（validation監視）、列/行サブサンプリング、L1/L2/葉の制約で過学習を抑える。 |
| SVM（補足） | support vector machine (details) | ヒンジ損失+正則化で最大マージン境界を得る。カーネル（RBF/多項式/線形）で非線形分離を実現。Cは誤分類許容、$\gamma$は境界の滑らかさを調整し、両者のバランスが決定境界の形状を規定する。 | 前処理で標準化必須。層化CVでC, $\gamma$を探索し、過適合時は$\gamma$を下げる/特徴を減らす。 |
| 交差検証（補足） | cross validation (details) | 前処理（スケーリング/エンコード/選択）は各fold内でfit→transformする。グループ依存/リークがある場合はGroupKFold、時系列は時系列CVを使い時間順を保つ。 | ハイパラ探索は検証データのみで行い、最終評価はテストに一度だけ。ネストCVで過適合を抑制。 |
| 確率校正 | probability calibration | モデルの出力確率を実確率に整える。Platt scaling（ロジ回による校正）やIsotonic回帰（単調な非線形校正）を用いる。校正曲線/信頼度曲線で品質を確認。 | 校正に用いたデータと評価データを分ける。分布が変われば再校正を検討。 |
| 閾値最適化 | threshold optimization | ROC/PR曲線や業務コスト（重み）に基づいて閾値を最適化する。期待コスト最小化やF1最大化、Youden indexなど目的に応じて基準を選ぶ。 | 不均衡タスクではPR曲線で最適化するのが実務的。群ごとの閾値分けも検討。 |
