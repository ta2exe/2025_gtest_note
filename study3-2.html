<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 3-2: 教師なし学習 - G-Test Note</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="assets/css/style.css">
    
    <!-- MathJax Configuration -->
    <script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            processEscapes: true,
            processEnvironments: true
        },
        options: {
            skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body class="chapter-magenta">
    <header class="header">
        <a href="index.html" class="logo">G-Test Note</a>
        <button class="hamburger" onclick="openMenu()">
            <i class="fas fa-bars"></i>
        </button>
    </header>

    <div class="container">
        <!-- Sidebar TOC -->
        <aside class="sidebar">
            <div class="chapter-title">Chapter 3-2: 教師なし学習</div>
            <nav class="toc" id="tableOfContents">
                <!-- TOC will be generated dynamically -->
            </nav>
        </aside>

        <!-- Main Content -->
        <main class="main-content study">
            <div class="content-header">
                <h1 class="content-title">Chapter 3-2</h1>
                <h2 class="content-subtitle">教師なし学習</h2>
                <div class="content-meta">
                    <span class="chapter-label">機械学習の概要</span>
                </div>
            </div>

            <div class="content">
                <h1 id="syllabus">シラバス対応</h1>
                
                <div style="background-color: #1a1a1a; border: 3px solid #000000; padding: 20px; margin: 20px 0;">
                    <h3 style="color: #ff00ff; margin-top: 0;">📋 学習目標</h3>
                    <p>教師なし学習の基本的な考え方を理解し、クラスタリングや次元削減などの主要な手法について説明できる。</p>
                    
                    <h3 style="color: #ff00ff; margin-top: 20px;">🔑 シラバス・キーワード</h3>
                    <ul>
                        <li><strong>教師なし学習</strong></li>
                        <li><strong>クラスタリング</strong></li>
                        <li><strong>k-means</strong></li>
                        <li><strong>主成分分析（PCA）</strong></li>
                        <li><strong>次元削減</strong></li>
                        <li><strong>次元の呪い</strong></li>
                    </ul>
                </div>

                <h1 id="overview">教師なし学習とは何か</h1>
                
                <p>教師なし学習（Unsupervised Learning）は、正解ラベルのないデータから隠れたパターンや構造を発見する機械学習手法です。教師あり学習とは対照的に、「正解」を教えることなく、データ自体が持つ内在的な特徴や関係性を見つけ出すことが目標です。</p>

                <p>この手法の価値を理解するために、探偵の仕事に例えてみましょう。教師あり学習が「犯人がわかっている事件から、犯行パターンを学習する」のに対し、教師なし学習は「手がかりしかない状況で、データから事件の全体像や犯人像を浮かび上がらせる」作業に似ています。</p>

                <p>現実世界では、正解ラベルが付いていないデータの方が圧倒的に多く存在します。企業の顧客データ、SNSの投稿、センサーから収集される時系列データなど、膨大なデータが蓄積されているものの、それらに明確な「正解」が付けられていないケースがほとんどです。教師なし学習は、こうした「宝の山」から価値のある洞察を抽出する重要な技術なのです。</p>

                <h1 id="comparison">教師あり学習との違い</h1>

                <p>教師あり学習と教師なし学習の違いを、具体例で比較してみましょう。</p>

                <div style="background-color: #1a1a1a; border: 3px solid #000000; padding: 20px; margin: 20px 0;">
                    <h3 style="color: #ff00ff; margin-top: 0;">🔄 学習方式の比較</h3>
                    
                    <h4 style="color: #ffffff;">教師あり学習の場合</h4>
                    <p><strong>問題設定</strong>：顧客の購買履歴と年齢・性別情報から、その顧客が「高価格商品を購入するか」を予測</p>
                    <p><strong>データ</strong>：[購買履歴, 年齢, 性別] → [高価格購入: Yes/No]</p>
                    <p><strong>目標</strong>：新規顧客の高価格商品購入可能性を予測</p>
                    
                    <h4 style="color: #ffffff; margin-top: 20px;">教師なし学習の場合</h4>
                    <p><strong>問題設定</strong>：顧客の購買履歴データから、似たような行動パターンを持つ顧客グループを発見</p>
                    <p><strong>データ</strong>：[購買履歴, 年齢, 性別]（正解ラベルなし）</p>
                    <p><strong>目標</strong>：顧客をいくつかのグループに分類し、各グループの特徴を理解</p>
                </div>

                <p>教師あり学習では「予測精度」が最重要指標ですが、教師なし学習では「発見した構造の意味やビジネス価値」が重要になります。正解がないため、結果の解釈や活用方法により創造性が求められる分野でもあります。</p>

                <h1 id="main-types">教師なし学習の主要タイプ</h1>

                <h2 id="clustering">クラスタリング（Clustering）</h2>

                <p>クラスタリングは、似たような特徴を持つデータを同じグループ（クラスター）にまとめる手法です。「類は友を呼ぶ」という考え方に基づいて、データを自然なグループに分割します。</p>

                <h3 id="clustering-intuition">クラスタリングの直感的理解</h3>

                <p>パーティー会場を想像してみてください。参加者は自然に似たような興味や関心を持つ人同士で小グループを作ります。クラスタリングは、この「自然な集まり」をデータから自動的に発見する技術です。</p>

                <p>ビジネスの世界では、顧客セグメンテーションが代表的な応用例です。年齢、収入、購買行動などの特徴から、顧客を「若年・高所得・ブランド志向」「中年・中所得・実用重視」「高齢・低所得・価格重視」といったグループに自動分類できます。</p>

                <h3 id="kmeans">k-means法</h3>

                <p>k-means法は最も広く使われているクラスタリング手法です。事前に作りたいクラスター数（k）を指定し、各データ点を最も近いクラスターの中心点（重心）に割り当てていきます。</p>

                <div style="background-color: #1a1a1a; border: 3px solid #000000; padding: 20px; margin: 20px 0;">
                    <h3 style="color: #ff00ff; margin-top: 0;">⚙️ k-meansのアルゴリズム</h3>
                    <ol>
                        <li><strong>初期化</strong>：k個のクラスター中心を適当に配置</li>
                        <li><strong>割り当て</strong>：各データ点を最も近い中心に割り当て</li>
                        <li><strong>更新</strong>：各クラスターの重心を再計算</li>
                        <li><strong>収束まで繰り返し</strong>：中心位置が変わらなくなるまで2-3を反復</li>
                    </ol>
                </div>

                <p>k-meansの距離計算には通常ユークリッド距離を使用します：</p>

                <div style="text-align: center; margin: 20px 0;">
                    $$d = \sqrt{(x_1-y_1)^2 + (x_2-y_2)^2 + \cdots + (x_n-y_n)^2}$$
                </div>

                <p>k-meansの課題は、事前にクラスター数kを決める必要があることです。実際の問題では、適切なk値を見つけるために「エルボー法」や「シルエット分析」などの手法を使います。</p>

                <h3 id="clustering-applications">クラスタリングの応用例</h3>

                <div style="background-color: #1a1a1a; border: 3px solid #000000; padding: 20px; margin: 20px 0;">
                    <h3 style="color: #ff00ff; margin-top: 0;">🎯 実用例</h3>
                    <ul>
                        <li><strong>マーケティング</strong>：顧客セグメンテーションによる個別戦略立案</li>
                        <li><strong>生物学</strong>：遺伝子発現パターンによる生物種分類</li>
                        <li><strong>画像処理</strong>：似た色やテクスチャ領域のグループ化</li>
                        <li><strong>推薦システム</strong>：類似ユーザー発見による協調フィルタリング</li>
                        <li><strong>異常検知</strong>：正常データクラスターから外れた点の検出</li>
                    </ul>
                </div>

                <h2 id="dimensionality-reduction">次元削減（Dimensionality Reduction）</h2>

                <p>次元削減は、高次元データを低次元空間に投影する技術です。データの本質的な情報を保ちながら、扱いやすい形に変換することが目標です。</p>

                <h3 id="curse-of-dimensionality">次元の呪い</h3>

                <p>なぜ次元削減が必要なのでしょうか？答えは「次元の呪い」と呼ばれる現象にあります。これは、データの次元（特徴量の数）が増えると、様々な問題が発生する現象です。</p>

                <p>具体例で説明しましょう。1次元（直線上）で2点間の距離を測るのは簡単です。2次元（平面上）でも直感的に理解できます。しかし、1000次元空間ではどうでしょうか？人間には想像もできない空間になってしまいます。</p>

                <p>高次元空間では以下の問題が発生します：</p>
                <ul>
                    <li><strong>計算量の爆発</strong>：処理時間とメモリ使用量が指数的に増加</li>
                    <li><strong>データの希薄化</strong>：データ点同士が平均的に遠くなり、近隣の概念が意味を失う</li>
                    <li><strong>可視化困難</strong>：3次元以上は直接的な可視化が不可能</li>
                    <li><strong>過学習の誘発</strong>：特徴量に対してデータ数が相対的に少なくなる</li>
                </ul>

                <h3 id="pca">主成分分析（PCA）</h3>

                <p>主成分分析（Principal Component Analysis, PCA）は、最も基本的で重要な次元削減手法です。データの分散（ばらつき）を最大化する方向を見つけ、その方向に沿って新しい座標軸を作成します。</p>

                <p>PCAの考え方を身近な例で説明しましょう。多くの人の身長と体重データがあるとします。この2次元データを1次元に削減する場合、PCAは「身長と体重の情報を最も効率よく表現できる軸」を見つけます。実際には、身長と体重は相関があるため、斜めの軸（例：「体格指数」のような軸）が最適になるでしょう。</p>

                <div style="background-color: #1a1a1a; border: 3px solid #000000; padding: 20px; margin: 20px 0;">
                    <h3 style="color: #ff00ff; margin-top: 0;">📊 PCAの手順</h3>
                    <ol>
                        <li><strong>データの標準化</strong>：特徴量のスケールを統一</li>
                        <li><strong>共分散行列の計算</strong>：特徴量間の関係を数値化</li>
                        <li><strong>固有値・固有ベクトルの算出</strong>：主成分の方向と重要度を決定</li>
                        <li><strong>主成分の選択</strong>：寄与率の高い成分を採用</li>
                        <li><strong>データ変換</strong>：新しい座標軸でデータを表現</li>
                    </ol>
                </div>

                <h3 id="pca-interpretation">PCAの解釈</h3>

                <p>PCAの結果として得られる主成分は、元の特徴量の線形結合として表現されます：</p>

                <div style="text-align: center; margin: 20px 0;">
                    $$PC_1 = a_1 X_1 + a_2 X_2 + \cdots + a_n X_n$$
                </div>

                <p>各係数（a₁, a₂, ...）の大きさと符号から、その主成分が何を表しているかを解釈できます。例えば、顧客データのPCAで第1主成分の係数が「年収（+0.7）、教育年数（+0.6）、居住面積（+0.5）」だった場合、この成分は「社会経済地位」を表していると解釈できるでしょう。</p>

                <h3 id="dimensionality-applications">次元削減の応用例</h3>

                <div style="background-color: #1a1a1a; border: 3px solid #000000; padding: 20px; margin: 20px 0;">
                    <h3 style="color: #ff00ff; margin-top: 0;">🎯 実用例</h3>
                    <ul>
                        <li><strong>画像圧縮</strong>：写真の主要な特徴のみを保持してファイルサイズ削減</li>
                        <li><strong>可視化</strong>：高次元データを2D/3Dで表示</li>
                        <li><strong>ノイズ除去</strong>：主要な信号成分のみを抽出</li>
                        <li><strong>前処理</strong>：機械学習モデルの入力次元数を削減</li>
                        <li><strong>特徴選択</strong>：重要な特徴量の自動抽出</li>
                    </ul>
                </div>

                <h1 id="other-methods">その他の教師なし学習手法</h1>

                <h2 id="association-rules">アソシエーション分析</h2>

                <p>アソシエーション分析は、データ項目間の関連性を発見する手法です。「商品Aを買う人は商品Bも買う傾向がある」といった関係性を見つけ出します。</p>

                <p>最も有名な例が「ビールとおむつ」の話です。実際には都市伝説的側面もありますが、金曜日の夕方にビールを買う男性客がついでにおむつも購入する傾向があることから、店舗レイアウトの最適化に活用されたという事例です。</p>

                <h2 id="anomaly-detection">異常検知</h2>

                <p>異常検知は、正常なパターンから大きく逸脱したデータを見つける手法です。クレジットカード不正利用検出、製造業での品質管理、サイバーセキュリティでの侵入検知など幅広く活用されています。</p>

                <p>基本的な考え方は「正常データの分布を学習し、そこから大きく外れたデータを異常とする」ことです。教師なし学習の文脈では、異常ラベルがないデータから異常を見つけ出すことに価値があります。</p>

                <h1 id="challenges">教師なし学習の課題と限界</h1>

                <h2 id="evaluation-difficulty">評価の困難さ</h2>

                <p>教師なし学習最大の課題は、結果の評価が主観的になりがちなことです。教師あり学習なら正解率で性能を測れますが、教師なし学習では「良いクラスタリング」や「適切な次元削減」の基準が曖昧です。</p>

                <p>例えば、顧客クラスタリングの結果として「20代女性」「30代男性」「40代女性」というグループができたとします。これは年齢と性別による自然な分類ですが、ビジネス的には「ブランド志向」「価格重視」「品質重視」といった購買行動による分類の方が有用かもしれません。</p>

                <h2 id="parameter-selection">パラメータ選択の困難さ</h2>

                <p>多くの教師なし学習手法では、事前にパラメータを設定する必要があります。k-meansのクラスター数k、PCAの主成分数などです。適切な値を決めるには、ドメイン知識と試行錯誤が必要になります。</p>

                <h2 id="interpretation-challenges">結果解釈の複雑さ</h2>

                <p>教師なし学習の結果は、しばしば複雑で解釈が困難です。特に高次元データでは、発見されたパターンが何を意味するのか理解するのに専門知識が必要になります。</p>

                <h1 id="practical-applications">実用的な応用と事例</h1>

                <h2 id="business-applications">ビジネス応用</h2>

                <p><strong>小売業</strong>：購買パターン分析により、商品の陳列最適化や在庫管理を改善。季節性や地域性を考慮したレコメンドシステムの構築。</p>

                <p><strong>金融業</strong>：取引パターンから異常取引を検出し、不正利用を防止。顧客行動分析による新商品開発やリスク評価。</p>

                <p><strong>製造業</strong>：センサーデータから機械の正常パターンを学習し、故障予知や品質管理に活用。</p>

                <h2 id="research-applications">研究・科学応用</h2>

                <p><strong>生物学</strong>：遺伝子発現データから病気のサブタイプを発見。創薬における化合物の分類と構造活性相関の解析。</p>

                <p><strong>心理学・社会学</strong>：アンケート調査データから潜在的な心理特性や社会構造を抽出。</p>

                <h1 id="exam-focus">試験対策のポイント</h1>

                <div style="background-color: #1a1a1a; border: 3px solid #000000; padding: 20px; margin: 20px 0;">
                    <h3 style="color: #ff00ff; margin-top: 0;">🎯 G検定で頻出する内容</h3>
                    <ul>
                        <li><strong>教師ありとの違い</strong>：正解ラベルの有無による学習方式の差異</li>
                        <li><strong>クラスタリングの概念</strong>：k-means法の基本的な動作原理</li>
                        <li><strong>次元削減の必要性</strong>：次元の呪いと対策</li>
                        <li><strong>PCAの用途</strong>：データ圧縮、可視化、前処理での役割</li>
                        <li><strong>応用分野</strong>：顧客分析、異常検知、推薦システムでの活用</li>
                    </ul>
                </div>

                <h2 id="common-mistakes">よくある間違い</h2>
                <div style="background-color: #1a1a1a; border: 3px solid #000000; padding: 20px; margin: 20px 0;">
                    <h3 style="color: #ffffff; margin-top: 0;">❌ 注意すべきポイント</h3>
                    <ul>
                        <li><strong>正解がないことの誤解</strong>：評価ができないわけではない</li>
                        <li><strong>k-meansのk値</strong>：事前に指定が必要（自動では決まらない）</li>
                        <li><strong>PCAと特徴選択の混同</strong>：PCAは新特徴量作成、特徴選択は既存から選択</li>
                        <li><strong>次元削減の情報損失</strong>：完璧な復元は通常不可能</li>
                    </ul>
                </div>

                <h1 id="summary">まとめ</h1>

                <p>教師なし学習は、正解ラベルなしでデータの隠れた構造やパターンを発見する機械学習手法です。クラスタリングと次元削減が二大手法で、それぞれk-means法とPCAが代表的なアルゴリズムとして挙げられます。</p>

                <p>この技術の真の価値は、<strong>未知の知識の発見</strong>にあります。予測精度を競う教師あり学習とは異なり、データに潜む新たな洞察を見つけ出すことで、ビジネス戦略の立案や科学的発見につながる可能性を秘めています。</p>

                <p>一方で、結果の解釈や評価に専門知識が必要であり、パラメータ調整も経験と試行錯誤が求められます。しかし、現代のビッグデータ時代において、ラベルなしデータから価値を抽出する教師なし学習の重要性はますます高まっています。</p>

                <h1 id="glossary">主な用語集</h1>
                
                <h2 id="key-terms">重要用語</h2>
                <dl style="margin: 20px 0;">
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">教師なし学習（Unsupervised Learning）</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">正解ラベルのないデータから、隠れたパターンや構造を発見する機械学習手法。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">クラスタリング（Clustering）</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">類似したデータを同じグループ（クラスター）にまとめる手法。顧客セグメンテーションなどに活用。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">k-means法</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">事前にクラスター数kを指定し、各データを最も近い重心に割り当てるクラスタリング手法。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">次元削減（Dimensionality Reduction）</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">高次元データを低次元空間に投影し、本質的情報を保ちながら扱いやすくする技術。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">主成分分析（PCA）</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">データの分散を最大化する主成分を見つけて次元削減を行う、最も基本的な手法。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">次元の呪い（Curse of Dimensionality）</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">次元数の増加に伴い、データの希薄化や計算量増大などの問題が発生する現象。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">クラスター</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">クラスタリング結果として形成される、類似データの集合。自然な分類や群れ。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">重心（Centroid）</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">クラスターの中心点。k-meansでは各クラスターの重心を繰り返し更新する。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">主成分（Principal Component）</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">PCAで抽出される、データの分散を最大化する方向の軸。元特徴量の線形結合で表現。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">寄与率</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">各主成分がデータ全体の分散のどの程度を説明するかを示す割合。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">アソシエーション分析</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">データ項目間の関連性やルールを発見する手法。「商品Aを買う人は商品Bも買う」など。</dd>
                    
                    <dt style="font-weight: bold; color: #ff00ff; margin-top: 15px;">異常検知（Anomaly Detection）</dt>
                    <dd style="margin-left: 20px; margin-bottom: 10px;">正常パターンから逸脱したデータを発見する手法。不正検知や品質管理に活用。</dd>
                </dl>

                <!-- Page Navigation -->
                <nav class="page-nav" style="border-top: 3px solid #000000; padding-top: 40px; margin-top: 40px;">
                    <div style="display: flex; justify-content: space-between; align-items: center;">
                        <a href="study3-1.html" style="color: #ffffff; text-decoration: none; border: 3px solid #000000; padding: 15px 20px; text-transform: uppercase; font-weight: 600; transition: all 0.2s ease;">
                            <i class="fas fa-chevron-left" style="margin-right: 8px; color: #ff00ff;"></i>
                            Back: 3-1
                        </a>

                        <a href="study3-3.html" style="color: #ffffff; text-decoration: none; border: 3px solid #000000; padding: 15px 20px; text-transform: uppercase; font-weight: 600; transition: all 0.2s ease;">
                            Next: 3-3
                            <i class="fas fa-chevron-right" style="margin-left: 8px; color: #ff00ff;"></i>
                        </a>
                    </div>
                </nav>
            </div>
        </main>
    </div>

    <!-- Hamburger Menu -->
    <div class="menu-overlay" id="menuOverlay">
        <div class="menu-header">
            <div class="menu-title">Menu</div>
            <button class="close-btn" onclick="closeMenu()">
                <i class="fas fa-times"></i>
            </button>
        </div>
        
        <ul class="menu-items">
            <li class="menu-item">
                <a href="sitemap.html" class="menu-link">
                    <i class="fas fa-map" style="margin-right: 8px; color: #ffffff;"></i>
                    Sitemap
                </a>
            </li>
            <li class="menu-item">
                <a href="help.html" class="menu-link">
                    <i class="fas fa-question-circle" style="margin-right: 8px; color: #ffffff;"></i>
                    Help
                </a>
            </li>
            <li class="menu-item">
                <a href="settings.html" class="menu-link">
                    <i class="fas fa-cog" style="margin-right: 8px; color: #ffffff;"></i>
                    Settings
                </a>
            </li>
        </ul>
    </div>

    <script src="assets/js/main.js"></script>
    <script src="assets/js/toc-generator.js"></script>
    <script>
        // Initialize page
        document.addEventListener('DOMContentLoaded', function() {
            // Generate table of contents from existing HTML content
            generateTableOfContents();
        });
    </script>
</body>
</html>